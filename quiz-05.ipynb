{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 05 - Parallel Computing, Reproducibility, and Containers\n",
    "\n",
    "### Instructions\n",
    "\n",
    "This quiz is based on the material covered in lectures 21 to 24. You may use\n",
    "any resources available to you, including the lecture notes and the internet.\n",
    "\n",
    "All the data required for this quiz can be found in the `data` folder within this repository. If you need to recreate the datasets, you can do so by running the Python script included in the `scripts-data-generation` folder. Please make sure that the following Python packages are installed:\n",
    "\n",
    "```bash\n",
    "pip install numpy pandas pyarrow dask dask-sql joblib SQLAlchemy\n",
    "```\n",
    "\n",
    "This notebook contains the questions you need to answer.\n",
    "If possible, please submit your answers as an `.html` file on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 01 - Parallelising a Function with Joblib\n",
    "\n",
    "Use `joblib` to parallelise the computation of squaring numbers in a large array. Import the required packages and write code that uses four cores to parallelise the computation.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "numbers = np.arange(1000000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your code here\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "numbers = np.arange(1000000)\n",
    "\n",
    "# Use joblib to parallelize the computation using four cores\n",
    "squared_numbers = Parallel(n_jobs=4)(delayed(square)(i) for i in numbers)\n",
    "\n",
    "# Optionally, convert the result back to a NumPy array\n",
    "squared_numbers = np.array(squared_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 02 - Using Dask Arrays for Large Data\n",
    "\n",
    "Using Dask's `array` module, create a Dask array of random numbers with 10,000 rows and 10,000 columns. The array should be divided into chunks of 1,000 rows by 1,000 columns to enable efficient parallel computation. Populate the array with random numbers drawn from a normal distribution, where the mean is 0 and the standard deviation is 1. After creating the array, compute the mean, standard deviation, maximum, and minimum of the array using Dask's parallel computation capabilities. Use the `.compute()` method to execute the computations and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.00019316936338155356\n",
      "Standard Deviation: 1.0000628347868312\n",
      "Maximum: 5.474412750877314\n",
      "Minimum: -5.786211933245348\n"
     ]
    }
   ],
   "source": [
    "# Please write your code here\n",
    "import dask.array as da\n",
    "\n",
    "# Define the shape and chunks of the array\n",
    "shape = (10000, 10000)\n",
    "chunks = (1000, 1000)\n",
    "\n",
    "# Create a Dask array with the specified shape and chunks\n",
    "dask_array = da.random.normal(0, 1, size=shape, chunks=chunks)\n",
    "\n",
    "# Compute the mean, standard deviation, maximum, and minimum\n",
    "mean = dask_array.mean().compute()\n",
    "std_dev = dask_array.std().compute()\n",
    "maximum = dask_array.max().compute()\n",
    "minimum = dask_array.min().compute()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n",
    "print(f\"Maximum: {maximum}\")\n",
    "print(f\"Minimum: {minimum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 03 - Dask DataFrame Operations with Parquet Files\n",
    "\n",
    "The `data` folder containts datasets for four countries—Brazil, India, UK, and USA—covering the years 1945 to 2023. Each country's data is stored in a separate Parquet file named after the country (`Brazil.parquet`, `India.parquet`, `UK.parquet`, `USA.parquet`). Each file contains the following columns:\n",
    "\n",
    "- `country` (string): The name of the country.\n",
    "- `year` (integer): The year of the record.\n",
    "- `gdp_per_capita` (float): The GDP per capita for that country and year.\n",
    "- `population` (integer): The population for that country and year.\n",
    "\n",
    "Using Dask's `dataframe` module, read _only the `country` and the `gdp_per_capita` columns_ from the Parquet files into a Dask DataFrame. Then, compute the mean and standard deviation of the GDP per capita for each country using Dask's parallel computation capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean GDP per Capita by Country:\n",
      "country\n",
      "Brazil     5496.292031\n",
      "India      1251.704443\n",
      "UK        27496.851363\n",
      "USA       40189.822290\n",
      "Name: gdp_per_capita, dtype: float64\n",
      "\n",
      "Standard Deviation of GDP per Capita by Country:\n",
      "country\n",
      "Brazil     2682.494158\n",
      "India       456.525628\n",
      "UK        10607.858036\n",
      "USA       14892.455747\n",
      "Name: gdp_per_capita, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Please write your code here\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Read the Parquet files\n",
    "df = dd.read_parquet('~/Documents/github/qtm350-quiz05/data/*.parquet', columns=['country', 'gdp_per_capita'])\n",
    "\n",
    "# Group by 'country' and compute the mean and standard deviation\n",
    "grouped = df.groupby('country')['gdp_per_capita']\n",
    "mean_gdp = grouped.mean().compute()\n",
    "std_gdp = grouped.std().compute()\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean GDP per Capita by Country:\")\n",
    "print(mean_gdp)\n",
    "print(\"\\nStandard Deviation of GDP per Capita by Country:\")\n",
    "print(std_gdp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 04 - Dask and SQL Queries\n",
    "\n",
    "Load the `data.csv` file into a Dask DataFrame and use the `dask_sql` package to perform a SQL query that selects the `country` and `gdp_per_capita` columns and filters the rows where `gdp_per_capita` is greater than 20000 in 2014. Display the results. Do not forget to register the Dask DataFrame as a SQL table with the `create_table` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    country  gdp_per_capita\n",
      "227      UK    40455.486012\n",
      "306     USA    65386.141694\n"
     ]
    }
   ],
   "source": [
    "# Please write your code here\n",
    "import dask.dataframe as dd\n",
    "from dask_sql import Context\n",
    "\n",
    "# Load the data into a Dask DataFrame\n",
    "df = dd.read_csv('~/Documents/github/qtm350-quiz05/data/data.csv')\n",
    "\n",
    "# Create a Dask SQL context\n",
    "c = Context()\n",
    "\n",
    "# Register the DataFrame as a SQL table named 'my_table'\n",
    "c.create_table('my_table', df)\n",
    "\n",
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT country, gdp_per_capita\n",
    "FROM my_table\n",
    "WHERE gdp_per_capita > 20000 AND year = 2014\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and compute the results\n",
    "result = c.sql(query).compute()\n",
    "\n",
    "# Display the results\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 05 - Parallelising a Function with Dask Delayed\n",
    "\n",
    "Suppose we need to compute the sum of squares of numbers for large ranges. The function below calculates the sum of squares from `0` up to `n-1`. Modify the given `sum_of_squares` function to use Dask's `@delayed` decorator and compute the sum of squares for each number in the numbers list in parallel. Measure and print the total execution time for the parallel computation, and print the results for each input number (as indicated in the code).\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "def sum_of_squares(n):\n",
    "    \"\"\"Compute the sum of squares from 0 to n-1.\"\"\"\n",
    "    return sum(i * i for i in range(n))\n",
    "\n",
    "numbers = [100_000_000, 200_000_000, 300_000_000, 400_000_000]\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform the computations serially\n",
    "results_serial = []\n",
    "for n in numbers:\n",
    "    result = sum_of_squares(n)\n",
    "    results_serial.append(result)\n",
    "    print(f\"Sum of squares up to {n}: {result}\")\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the total execution time\n",
    "serial_execution_time = end_time - start_time\n",
    "print(f\"\\nSerial execution time: {serial_execution_time:.2f} seconds\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of squares up to 100000000: 333333328333333350000000\n",
      "Sum of squares up to 200000000: 2666666646666666700000000\n",
      "Sum of squares up to 300000000: 8999999955000000050000000\n",
      "Sum of squares up to 400000000: 21333333253333333400000000\n",
      "\n",
      "Parallel execution time: 44.93 seconds\n"
     ]
    }
   ],
   "source": [
    "# Please write your code here\n",
    "import time\n",
    "from dask import delayed, compute\n",
    "\n",
    "# Use Dask's delayed decorator\n",
    "@delayed\n",
    "def sum_of_squares(n):\n",
    "    \"\"\"Compute the sum of squares from 0 to n-1.\"\"\"\n",
    "    return sum(i*i for i in range(n))\n",
    "\n",
    "numbers = [100_000_000, 200_000_000, 300_000_000, 400_000_000]\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a list of delayed computations\n",
    "delayed_results = [sum_of_squares(n) for n in numbers]\n",
    "\n",
    "# Compute the results in parallel\n",
    "results_parallel = compute(*delayed_results)\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the results\n",
    "for n, result in zip(numbers, results_parallel):\n",
    "    print(f\"Sum of squares up to {n}: {result}\")\n",
    "\n",
    "# Calculate and print the total execution time\n",
    "parallel_execution_time = end_time - start_time\n",
    "print(f\"\\nParallel execution time: {parallel_execution_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 06 - Using `pip` and `requirements.txt` for Dependency Management\n",
    "\n",
    "Explain how you can use `pip` to manage dependencies in a Python project. Describe the process of generating a `requirements.txt` file from your current environment and how to use this file to install the same packages in another environment or on a different machine. Please comment your code to explain each step."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Please write your code here\n",
    "# Generate a requirements.txt file from your current environment\n",
    "pip freeze > requirements.txt\n",
    "# Install packages from the requirements.txt file\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 07 - Creating and Sharing a Conda Environment\n",
    "\n",
    "Describe the steps to create a new Conda virtual environment named `qtm350` with Python 3.12 and install the packages `numpy`, `pandas`, and `matplotlib`. Explain how to export this environment to an `environment.yml` file and how someone else can recreate the same environment on their machine using this file. Please comment your code to explain each step. There is no need to run the code for this question, but you can do so if you wish."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Please write your code here\n",
    "# Create a new Conda environment named 'qtm350' with Python 3.12 and install packages\n",
    "conda create -n qtm350 python=3.12 numpy pandas matplotlib\n",
    "\n",
    "# Activate the new environment\n",
    "conda activate qtm350\n",
    "\n",
    "# After installing any additional packages, export the environment to a YAML file\n",
    "conda env export > environment.yml\n",
    "\n",
    "# Create the environment from the YAML file\n",
    "conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 08 - Writing a Simple Dockerfile\n",
    "\n",
    "Write a simple `Dockerfile` that creates a Docker image for a Python application. The application consists of a single Python script named `app.py` that prints \"Hello, World!\" when executed. The `Dockerfile` should use the official Python image as the base image and copy the `app.py` script into the image. When the container is run, it should execute the `app.py` script and print \"Hello, World!\"."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Please write your code here (no need to run it)\n",
    "\n",
    "# Use the official Python image as the base image\n",
    "FROM python:3.12-slim\n",
    "\n",
    "# Set the working directory inside the container\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the app.py script into the container\n",
    "COPY app.py /app/\n",
    "\n",
    "# Specify the command to run when the container starts\n",
    "CMD [\"python\", \"app.py\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 09 - Writing a Dockerfile to Install Software on a Base Image\n",
    "\n",
    "Create a Dockerfile that starts from an Ubuntu 24.04 base image and installs the following software:\n",
    "\n",
    "- Git version 2.43.0-1ubuntu7.1\n",
    "- SQLite version 3.45.1-1ubuntu2\n",
    "\n",
    "Ensure that you specify the exact versions of the packages. Include commands to clean up the package manager cache after installation to reduce the image size."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Please write your code here (no need to run it)\n",
    "\n",
    "# Start from Ubuntu 24.04 base image\n",
    "FROM ubuntu:24.04\n",
    "\n",
    "# Install specific versions of git and sqlite3\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y \\\n",
    "    git=1:2.43.0-1ubuntu7.1 \\\n",
    "    sqlite3=3.45.1-1ubuntu2 && \\\n",
    "    # Clean up the package manager cache to reduce the image size\n",
    "    rm -rf /var/lib/apt/lists/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Question 10 - Writing a Dockerfile to Install Python and Packages on Ubuntu\n",
    "\n",
    "Write a `Dockerfile` that starts from an Ubuntu 24.04 base image, installs Python 3.12 and `pip`, and then uses `pip` to install specific versions of `numpy` (1.26.4), `pandas` (2.2.2), and `matplotlib` (3.9.2). Ensure you include commands to clean up the package manager cache after installation to reduce the image size. Set up a working directory named `app/` and configure the container to start an interactive Python shell `python3` by default."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Please write your code here (no need to run it)\n",
    "\n",
    "# Start from Ubuntu 24.04 base image\n",
    "FROM ubuntu:24.04\n",
    "\n",
    "# Install Python 3.12 and pip\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y \\\n",
    "    python3.12 \\\n",
    "    python3-pip && \\\n",
    "    # Clean up the package manager cache\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install specific versions of numpy, pandas, and matplotlib using pip\n",
    "RUN pip3 install numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.2\n",
    "\n",
    "# Set up the working directory\n",
    "WORKDIR /app/\n",
    "\n",
    "# Configure the container to start an interactive Python shell by default\n",
    "CMD [\"python3\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
